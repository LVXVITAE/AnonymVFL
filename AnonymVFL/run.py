import os
import warnings

# åœ¨å¯¼å…¥ JAX ä¹‹å‰è®¾ç½®
os.environ['JAX_PLATFORMS'] = 'cpu'
os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=1 --xla_cpu_multi_thread_eigen=false'
os.environ['OMP_NUM_THREADS'] = '1'

# è¿‡æ»¤ç‰¹å®šè­¦å‘Š
warnings.filterwarnings('ignore', category=RuntimeWarning, module='subprocess')
# å±è”½æ‰€æœ‰è­¦å‘Š
warnings.filterwarnings('ignore')


from common import MPCInitializer
from secretflow.data.ndarray import load
import secretflow as sf
import pandas as pd
import numpy as np
import argparse

def main(args : argparse.Namespace):
    cluster_def = {}
    if args.mode == 'multi_sim' or args.mode == 'multi_distributed':
        company_spu_ip, company_spu_port = args.company_spu_addr.split(':')
        partner_spu_ip, partner_spu_port = args.partner_spu_addr.split(':')
        coordinator_spu_ip, coordinator_spu_port = args.coordinator_spu_addr.split(':')
        # æ·»åŠ ç›‘å¬ç«¯å£ä¿¡æ¯è¾“å‡º
        print("=" * 60)
        print("ğŸš€ å¤šæ–¹å®‰å…¨è®¡ç®—èŠ‚ç‚¹å¯åŠ¨ä¿¡æ¯")
        print("=" * 60)
        print(f"ğŸ“ Company èŠ‚ç‚¹ç›‘å¬åœ°å€:    {args.company_spu_addr}")
        print(f"ğŸ“ Partner èŠ‚ç‚¹ç›‘å¬åœ°å€:    {args.partner_spu_addr}")
        print(f"ğŸ“ Coordinator èŠ‚ç‚¹ç›‘å¬åœ°å€: {args.coordinator_spu_addr}")
        print(f"ğŸŒ Ray Head åœ°å€:          {args.ray_head_addr}")
        print("=" * 60)
        
        cluster_def['nodes'] = [
            {
                'party': 'company',
                # Please choose an unused port.
                'address': args.company_spu_addr,
                'listen_addr': f'0.0.0.0:{company_spu_port}'
            },
            {
                'party': 'partner',
                # Please choose an unused port.
                'address': args.partner_spu_addr,
                'listen_addr': f'0.0.0.0:{partner_spu_port}'
            },
            {
                'party': 'coordinator',
                # Please choose an unused port.
                'address': args.coordinator_spu_addr,
                'listen_addr': f'0.0.0.0:{coordinator_spu_port}'
            }
        ]
        cluster_def['runtime_config'] = {
            'protocol': 3,
            'field': 3
        }
    mpc_init = MPCInitializer(args.mode, args.ray_head_addr,cluster_def)
    company, partner, coordinator = mpc_init.company, mpc_init.partner, mpc_init.coordinator
    spu = mpc_init.spu

    # è®¾ç½®è®¾å¤‡
    devices = {
        'spu': spu,
        'company': company,
        'partner': partner,
        'coordinator': coordinator,
    }


    if args.run_psi:
        print("\n" + "=" * 60)
        print("ğŸ”’ å¼€å§‹æ‰§è¡Œç§æœ‰é›†åˆæ±‚äº¤ (PSI)")
        print("=" * 60)
        print(f"ğŸ“‚ Company è®­ç»ƒæ•°æ®: {args.path_to_company_train_dataset}")
        print(f"ğŸ“‚ Partner è®­ç»ƒæ•°æ®:  {args.path_to_partner_train_dataset}")
        
        heu_devices = (mpc_init.company_heu, mpc_init.partner_heu)

        def read_dataset(path: str):
            data = pd.read_csv(path)
            keys = data.iloc[:, 0].astype(str).tolist()
            private_features = data.iloc[:, 1:].to_numpy(dtype=np.float32)
            header = data.columns.tolist()
            return (keys, private_features,None), header

        company_data, company_header = company(read_dataset,num_returns=2)(args.path_to_company_train_dataset)
        partner_data, partner_header = partner(read_dataset,num_returns=2)(args.path_to_partner_train_dataset)
        company_header = sf.reveal(company_header)[1:]
        partner_header = sf.reveal(partner_header)[1:]
        #è¾“å‡ºäº¤é›†çš„åˆ—æ ‡é¢˜
        header = company_header + partner_header
        # è®°å½•åˆ†éš”åˆ—çš„ç´¢å¼•ã€‚ç´¢å¼•å·¦ä¾§åˆ—ä¸ºcompanyçš„ç‰¹å¾ï¼Œå³ä¾§åˆ—ä¸ºpartnerçš„ç‰¹å¾
        if 'Revenue' in company_header:
            train_label_keeper = company
        elif 'Revenue' in partner_header:
            train_label_keeper = partner
        else:
            raise ValueError("Label column 'Revenue' must be present in either company or partner dataset")
        #è®°å½•æ ‡ç­¾åˆ—çš„ç´¢å¼•
        y_col = header.index('Revenue')

        from PSI import private_set_intersection
        company_share, partner_share, bucket_labels = private_set_intersection(company_data, partner_data,heu_devices)
        
        print(f"\nğŸ’¾ ä¿å­˜åŠ æ³•ç§˜å¯†å…±äº«åˆ†ç‰‡...")
        print(f"ğŸ“ Company ç§˜å¯†å…±äº«åˆ†ç‰‡: {args.path_to_company_share}")
        print(f"ğŸ“ Partner ç§˜å¯†å…±äº«åˆ†ç‰‡:  {args.path_to_partner_share}")
        company_share.device(np.savetxt)(args.path_to_company_share,company_share, delimiter=',')
        partner_share.device(np.savetxt)(args.path_to_partner_share,partner_share, delimiter=',')
    
        print(f"\nğŸ” æ˜¾ç¤ºå‰10è¡Œæ•°æ®")
        print("-" * 80)
        
        # # è·å–æ˜æ–‡æ•°æ®è¿›è¡Œå¯¹æ¯” - ä¿®æ­£ï¼šå¤„ç†å…ƒç»„æ ¼å¼çš„æ•°æ®
        # company_data_revealed = sf.reveal(company_data)
        # partner_data_revealed = sf.reveal(partner_data)

        # # æå–å®é™…çš„ç‰¹å¾æ•°æ®ï¼ˆç¬¬äºŒä¸ªå…ƒç´ æ˜¯private_featuresï¼‰
        # company_features = company_data_revealed[1][:10]  # private_features
        # partner_features = partner_data_revealed[1][:10]  # private_features

        company_share_revealed = sf.reveal(company_share)[:10]
        partner_share_revealed = sf.reveal(partner_share)[:10]

        # print("ğŸ“Š Company åŸå§‹æ•°æ® (å‰10è¡Œå‰5åˆ—):")
        # print(company_features[:, :5])
        print(f"ğŸ“Š Company ç§˜å¯†å…±äº«åˆ†ç‰‡ (å‰10è¡Œå‰5åˆ—):")
        print(company_share_revealed[:, :5])

        # print("\nğŸ“Š Partner åŸå§‹æ•°æ® (å‰10è¡Œå‰5åˆ—):")
        # print(partner_features[:, :5])
        print(f"ğŸ“Š Partner ç§˜å¯†å…±äº«åˆ†ç‰‡ (å‰10è¡Œå‰5åˆ—):")
        print(partner_share_revealed[:, :5])
        
        # print("ğŸ” æœ€åŸå§‹çš„è¾“å…¥æ•°æ®:")
        # print("CompanyåŸå§‹æ•°æ®å‰5è¡Œ:", sf.reveal(company_data)[1][:5])
        # print("PartneråŸå§‹æ•°æ®å‰5è¡Œ:", sf.reveal(partner_data)[1][:5])
        
        #  # éªŒè¯åŠ æ³•ç§˜å¯†å…±äº«çš„æ­£ç¡®æ€§
        # print(f"\nâœ… ç§˜å¯†å…±äº«éªŒè¯:")
        # reconstructed = company_share_revealed + partner_share_revealed
        # print(f"ğŸ“Š é‡æ„æ•°æ® (Companyåˆ†ç‰‡ + Partneråˆ†ç‰‡ï¼Œå‰10è¡Œå‰5åˆ—):")
        # print(reconstructed[:, :5])
        
        # # è®¡ç®—åŸå§‹æ•°æ®çš„æ‹¼æ¥ï¼ˆç”¨äºéªŒè¯ï¼‰
        # original_combined = np.hstack([company_data_revealed, partner_data_revealed])
        # print(f"ğŸ“Š åŸå§‹æ•°æ®æ‹¼æ¥ (Company + Partnerï¼Œå‰10è¡Œå‰5åˆ—):")
        # print(original_combined[:, :5])
        
        # # æ£€æŸ¥æ˜¯å¦ç›¸ç­‰
        # max_diff = np.max(np.abs(reconstructed - original_combined))
        # print(f"ğŸ” é‡æ„è¯¯å·® (æœ€å¤§ç»å¯¹å·®å€¼): {max_diff:.6f}")
        # if max_diff < 1e-6:
        #     print("âœ… ç§˜å¯†å…±äº«é‡æ„æˆåŠŸï¼")
        # else:
        #     print("âŒ ç§˜å¯†å…±äº«é‡æ„å­˜åœ¨è¯¯å·®ï¼")
        
        print("=" * 60)
    else:
        if args.path_to_company_share.endswith('.csv'):
            company_share = company(np.loadtxt)(args.path_to_company_share_save, delimiter=',')
        elif args.path_to_company_share.endswith('.npy'):
            company_share = company(np.load)(args.path_to_company_share_save)
        else:
            raise ValueError("Unsupported file format for company share. Use .csv or .npy")
        if args.path_to_partner_share.endswith('.csv'):
            partner_share = partner(np.loadtxt)(args.path_to_partner_share, delimiter=',')
        elif args.path_to_partner_share.endswith('.npy'):
            partner_share = partner(np.load)(args.path_to_partner_share)
        else:
            raise ValueError("Unsupported file format for partner share. Use .csv or .npy")



    def split_X_y(share, y_col):
        X = np.delete(share, y_col, axis=1)
        y = share[:, y_col].reshape(-1, 1)
        return X, y

    def share2spu(company_share, partner_share):
        company_share = company_share.to(spu)
        partner_share = partner_share.to(spu)
        return spu(lambda x, y : x + y)(company_share, partner_share)

    X_train_company, y_train_company = company(split_X_y,num_returns=2)(company_share,y_col)
    X_train_partner, y_train_partner = partner(split_X_y,num_returns=2)(partner_share,y_col)
    X_train = share2spu(X_train_company, X_train_partner)
    if args.share_y:
        y_train = train_label_keeper(lambda x, y : x + y)(y_train_company.to(train_label_keeper), y_train_partner.to(train_label_keeper))
    else:
        y_train = share2spu(y_train_company, y_train_partner)

    def read_val_dataset(path):
        data = pd.read_csv(path)
        features = data.iloc[:, 1:].to_numpy(dtype=np.float32)
        header = data.columns.tolist()
        return features, header
    if args.path_to_company_val_dataset is not None and args.path_to_partner_val_dataset is not None:
        test_company, test_company_header = company(read_val_dataset, num_returns=2)(args.path_to_company_val_dataset)
        test_partner, test_partner_header = partner(read_val_dataset, num_returns=2)(args.path_to_partner_val_dataset)
        test_company_header = sf.reveal(test_company_header)[1:]
        test_partner_header = sf.reveal(test_partner_header)[1:]
        if 'Revenue' in test_company_header:
            y_col= test_company_header.index('Revenue')
            X_test_company, y_test = company(split_X_y,num_returns=2)(test_company,y_col)
            X_test_partner = test_partner
        elif 'Revenue' in test_partner_header:
            y_col= test_partner_header.index('Revenue')
            X_test_partner, y_test = partner(split_X_y,num_returns=2)(test_partner,y_col)
            X_test_company = test_company
        else:
            raise ValueError("Label column 'Revenue' must be present in either company or partner validation dataset")
        X_test = load({company: X_test_company, partner: X_test_partner})        
    else:
        X_test = None
        y_test = None

    from LR import SSLR
    
    print(f"\nğŸ¤– å¼€å§‹è®­ç»ƒè”é‚¦é€»è¾‘å›å½’æ¨¡å‹")
    print("=" * 60)
    print(f"ğŸ“ˆ è®­ç»ƒå‚æ•°:")
    print(f"   â€¢ è®­ç»ƒè½®æ•°: {args.n_epochs}")
    print(f"   â€¢ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   â€¢ å­¦ä¹ ç‡:   {args.lr}")
    print(f"   â€¢ éªŒè¯é¢‘ç‡: æ¯ {args.val_steps} æ­¥")
    print(f"   â€¢ æ ‡ç­¾å…±äº«: {'æ˜¯' if args.share_y else 'å¦'}")
    print("=" * 60)

    model = SSLR(devices, approx=args.share_y)
    accs = model.fit(X_train, y_train, X_test, y_test, n_epochs=args.n_epochs, batch_size=args.batch_size, val_steps=args.val_steps, lr=args.lr)
    if hasattr(args, 'path_to_company_model_save_dir') and hasattr(args, 'path_to_partner_model_save_dir'):
        print(f"\nğŸ’¾ ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡")
        print("=" * 60)
        print(f"ğŸ“ Company æ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„: {args.path_to_company_model_save_dir}")
        print(f"ğŸ“ Partner æ¨¡å‹æƒé‡ä¿å­˜è·¯å¾„:  {args.path_to_partner_model_save_dir}")
        model.save({
            'company': args.path_to_company_model_save_dir,
            'partner': args.path_to_partner_model_save_dir,
        },ext='csv')
        
        print(f"âœ… æ¨¡å‹æƒé‡å·²æˆåŠŸä¿å­˜ï¼")
        print(f"ğŸ“Š æƒé‡æ–‡ä»¶:")
        print(f"   â€¢ {args.path_to_company_model_save_dir}/weight.csv")
        print(f"   â€¢ {args.path_to_company_model_save_dir}/info.json")
        print(f"   â€¢ {args.path_to_partner_model_save_dir}/weight.csv")
        print(f"   â€¢ {args.path_to_partner_model_save_dir}/info.json")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(prog="AnonymVFL",description="è¿è¡ŒåŒ¿è¸ªå¯¹é½å’ŒåŒ¿è¸ªå­¦ä¹ ")
    parser.add_argument('--mode', type=str, default='single_sim', choices=['single_sim', 'multi_sim', 'multi_distributed'], help='è¿è¡Œæ¨¡å¼ï¼Œsingle_simç”¨äºå•æœºè¿è¡Œï¼Œmulti_simç”¨äºå±€åŸŸç½‘å¤šæœºè¿è¡Œï¼Œmulti_distributedç”¨äºçœŸæ­£åˆ†å¸ƒå¼è¿è¡Œ')
    parser.add_argument('--party', type=str, choices=['company', 'partner', 'coordinator'], help='åœ¨multi_distributedæ¨¡å¼ä¸‹æŒ‡å®šå½“å‰èŠ‚ç‚¹çš„è§’è‰²')
    parser.add_argument('--ray_head_addr', type=str, default="", help='Rayé›†ç¾¤çš„å¤´èŠ‚ç‚¹åœ°å€')
    parser.add_argument('--company_spu_addr', type=str, required=False, help='Company SPUçš„åœ°å€ï¼Œæ³¨æ„ä¸è¦å’ŒRayç«¯å£å†²çª')
    parser.add_argument('--partner_spu_addr', type=str, required=False, help='Partner SPUçš„åœ°å€ï¼Œæ³¨æ„ä¸è¦å’ŒRayç«¯å£å†²çª')
    parser.add_argument('--coordinator_spu_addr', type=str, required=False, help='Coordinator SPUçš„åœ°å€ï¼Œæ³¨æ„ä¸è¦å’ŒRayç«¯å£å†²çª')
    parser.add_argument('--run_psi', type=bool, default=True, help='æ˜¯å¦è¿è¡ŒPSI')
    parser.add_argument('--path_to_company_train_dataset', type=str, default="", help='Companyç«¯è®­ç»ƒé›†è·¯å¾„ã€‚æ•°æ®é›†åº”ä¸ºæ˜æ–‡csvæ–‡ä»¶ã€‚')
    parser.add_argument('--path_to_partner_train_dataset', type=str, default="", help='Partnerç«¯è®­ç»ƒé›†è·¯å¾„ã€‚æ•°æ®é›†åº”ä¸ºæ˜æ–‡csvæ–‡ä»¶ã€‚')
    parser.add_argument('--path_to_company_share', type=str, default="", help='Companyç«¯PSIè¾“å‡ºå…±äº«åˆ†ç‰‡ä¿å­˜è·¯å¾„ã€‚å¦‚è¿è¡ŒPSIï¼Œä¿å­˜åˆ°è¯¥è·¯å¾„ï¼›å¦‚ä¸è¿è¡ŒPSIï¼Œä»è¯¥è·¯å¾„è¯»å–åˆ†ç‰‡')
    parser.add_argument('--path_to_partner_share', type=str, default="", help='Partnerç«¯PSIè¾“å‡ºå…±äº«åˆ†ç‰‡ä¿å­˜è·¯å¾„ã€‚å¦‚è¿è¡ŒPSIï¼Œä¿å­˜åˆ°è¯¥è·¯å¾„ï¼›å¦‚ä¸è¿è¡ŒPSIï¼Œä»è¯¥è·¯å¾„è¯»å–åˆ†ç‰‡')
    parser.add_argument('--share_y', type=bool, default=False, help='æ˜¯å¦ç§˜å¯†å…±äº«å…±äº«æ ‡ç­¾y')
    parser.add_argument('--path_to_company_val_dataset', type=str, default="", help='Companyç«¯éªŒè¯é›†è·¯å¾„ã€‚æ•°æ®é›†åº”ä¸ºæ˜æ–‡csvæ–‡ä»¶ã€‚')
    parser.add_argument('--path_to_partner_val_dataset', type=str, default="", help='Partnerç«¯éªŒè¯é›†è·¯å¾„ã€‚æ•°æ®é›†åº”ä¸ºæ˜æ–‡csvæ–‡ä»¶ã€‚')
    parser.add_argument('--model', type=str, default='SSLR', choices=['SSLR', 'SSXGBoost'], help='é€‰æ‹©è¦è¿è¡Œçš„æ¨¡å‹')
    parser.add_argument('--n_epochs', type=int, default=10, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=1024, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--val_steps', type=int, default=1, help='æ¯éš”å¤šå°‘æ­¥åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ä¸€æ¬¡')
    parser.add_argument('--lr', type=float, default=0.1, help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--path_to_company_model_save_dir', type=str, required=False, help='Companyç«¯æ¨¡å‹ä¿å­˜è·¯å¾„')
    parser.add_argument('--path_to_partner_model_save_dir', type=str, required=False, help='Partnerç«¯æ¨¡å‹ä¿å­˜è·¯å¾„')
    args = parser.parse_args()
    main(args)