{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d2d756",
   "metadata": {},
   "source": [
    "# XGBoost运行示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089337be",
   "metadata": {},
   "source": [
    "以下示例仅用于说明XGBoost的工作流程，目前仅支持单机测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e40681",
   "metadata": {},
   "source": [
    "加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a84071af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PSI import PSICompany, PSIPartner\n",
    "\n",
    "project_dir = os.path.dirname(os.path.abspath(''))\n",
    "data_dir = os.path.join(project_dir, 'Datasets', 'data', 'data')\n",
    "host_data = pd.read_csv(os.path.join(data_dir, 'breast_hetero_host.csv'))\n",
    "guest_data = pd.read_csv(os.path.join(data_dir, 'breast_hetero_guest.csv'))\n",
    "\n",
    "company_key, company_features = host_data['id'], host_data.drop(columns=['id'])\n",
    "partner_key, partner_features = guest_data['id'], guest_data.drop(columns=['id'])\n",
    "company_key = company_key.astype(str)\n",
    "partner_key = partner_key.astype(str)\n",
    "company_features = company_features.to_numpy()\n",
    "partner_features = partner_features.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ffeb2",
   "metadata": {},
   "source": [
    "XGBoost需要在PSI开始之前预先分桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from XGBoost import quantize_buckets\n",
    "import numpy as np\n",
    "\n",
    "Quantiles1, _, buckets_labels1 = quantize_buckets(company_features, k=50)\n",
    "Quantiles2, _, buckets_labels2 = quantize_buckets(partner_features[:,:-1], k=50) #最后一列是y无需分桶\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d56da",
   "metadata": {},
   "source": [
    "PSI\n",
    "\n",
    "注意此处每条数据每个属性的分桶标签作为public_features传入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b4d52db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing masked company cipher\n",
      "Computing masked partner cipher\n",
      "Computing company shares\n",
      "Computing partner shares\n"
     ]
    }
   ],
   "source": [
    "company = PSICompany(company_key, company_features, buckets_labels1)\n",
    "partner = PSIPartner(partner_key, partner_features, buckets_labels2)\n",
    "\n",
    "U_c, company_pk = company.exchange()\n",
    "E_c, U_p, partner_pk = partner.exchange(U_c, company_pk)\n",
    "L, R_cI = company.compute_intersection(E_c, U_p, partner_pk)\n",
    "R_pI = partner.output_shares(L)\n",
    "company_share = R_cI[0]\n",
    "partner_share = R_pI[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648df6e2",
   "metadata": {},
   "source": [
    "获取交集的分桶标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34ebf7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_buckets_labels = R_cI[1]\n",
    "partner_buckets_labels = R_pI[1]\n",
    "buckets_labels = np.concatenate((company_buckets_labels, partner_buckets_labels), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04399ca",
   "metadata": {},
   "source": [
    "此时share是`np.ndarray`类型。下面将其放入秘密共享设备spu中。\n",
    "目前我暂时还没有找到由share直接构造`SPUObject`的方法。可以暂时使用这个方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebe3057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import MPCInitializer, sigmoid, softmax\n",
    "import secretflow as sf\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "mpc_init = MPCInitializer()\n",
    "company, partner, coordinator, spu = mpc_init.company, mpc_init.partner, mpc_init.coordinator, mpc_init.spu\n",
    "# 假设y由company持有\n",
    "label_holder = company\n",
    "\n",
    "def share2spu(X1 : np.ndarray, X2 : np.ndarray):\n",
    "    \"\"\"\n",
    "    X1：由Company持有的share\n",
    "    X2：由Partner持有的share\n",
    "    \"\"\"    \n",
    "    X1, X2 = jnp.array(X1,dtype=jnp.float32), jnp.array(X2,dtype=jnp.float32)\n",
    "    # 将X1，X2分别移动到spu\n",
    "    X1 = sf.to(company, X1).to(spu)\n",
    "    X2 = sf.to(partner, X2).to(spu)\n",
    "    # 再在spu内部相加，得到秘密共享的变量X\n",
    "    def add(X1, X2):\n",
    "        \"\"\"\n",
    "        在SPU中执行加法操作\n",
    "        \"\"\"\n",
    "        return X1 + X2\n",
    "    return spu(add)(X1, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1d225",
   "metadata": {},
   "source": [
    "划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_1, test_1, train_2, test_2, buckets_labels_train, buckets_labels_test = train_test_split(\n",
    "    company_share, partner_share, buckets_labels)\n",
    "train_X1, train_y1 = train_1[:, :-1], train_1[:, -1].reshape(-1,1)\n",
    "train_X2, train_y2 = train_2[:, :-1], train_2[:, -1].reshape(-1,1)\n",
    "test_X1, test_y1 = test_1[:, :-1], test_1[:, -1].reshape(-1,1)\n",
    "test_X2, test_y2 = test_2[:, :-1], test_2[:, -1].reshape(-1,1)\n",
    "\n",
    "train_X = share2spu(train_X1, train_X2)\n",
    "from secretflow.data.ndarray import load, PartitionWay\n",
    "np.save(\"test_X1.npy\", test_X1)\n",
    "np.save(\"test_X2.npy\", test_X2)\n",
    "test_X = load({company: \"test_X1.npy\", partner: \"test_X2.npy\"})\n",
    "train_y = share2spu(train_y1, train_y2).to(label_holder)\n",
    "# 目前的模型在推理状态下，预测值按公开处理，因此测试集的y也公开\n",
    "test_y = test_y1 + test_y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236861e",
   "metadata": {},
   "source": [
    "将分桶标签整理恢复为桶列表\n",
    "\n",
    "桶列表中每个元素`bucket_j`是特征`j`的桶列表。`bucket_j`中的每个元素是一个一维数组，表示一个桶。桶里面保存每个元素在`X`中的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c87d072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from XGBoost import recover_buckets\n",
    "buckets_train = recover_buckets(buckets_labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c39cf",
   "metadata": {},
   "source": [
    "对分位点进行整理，需要整理为联邦数组形式和秘密共享形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f812551",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Quantiles1.npy\", Quantiles1)\n",
    "np.save(\"Quantiles2.npy\", Quantiles2)\n",
    "FedQuantiles = load({company: \"Quantiles1.npy\", partner: \"Quantiles2.npy\"}, partition_way=PartitionWay.HORIZONTAL)\n",
    "\n",
    "Quantiles1 = sf.to(company, jnp.array(Quantiles1)).to(spu)\n",
    "Quantiles2 = sf.to(partner, jnp.array(Quantiles2)).to(spu)\n",
    "# 将分桶标签转换为SPU上的格式\n",
    "def concat(Quantiles1, Quantiles2):\n",
    "    \"\"\"\n",
    "    将两个分桶标签拼接在一起\n",
    "    \"\"\"\n",
    "    return jnp.concatenate((Quantiles1, Quantiles2), axis=1)\n",
    "SSQuantiles = spu(concat)(Quantiles1, Quantiles2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749cd26",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d6ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lvx_vitae/AnonymVFL/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-28 23:21:19,224\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-07-28 23:21:19,545\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/lvx_vitae/AnonymVFL/.conda/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_monkey.py:840: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  return getattr(_posixsubprocess, original_name)(args, *other_args)\n",
      "/home/lvx_vitae/AnonymVFL/.conda/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_monkey.py:840: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  return getattr(_posixsubprocess, original_name)(args, *other_args)\n",
      "2025-07-28 23:21:43,058\tERROR services.py:1353 -- Failed to start the dashboard \n",
      "2025-07-28 23:21:43,059\tERROR services.py:1378 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2025-07-28 23:21:43,060\tERROR services.py:1388 -- Couldn't read dashboard.log file. Error: [Errno 2] No such file or directory: '/tmp/ray/session_2025-07-28_23-21-19_754726_36645/logs/dashboard.log'. It means the dashboard is broken even before it initializes the logger (mostly dependency issues). Reading the dashboard.err file which contains stdout/stderr.\n",
      "2025-07-28 23:21:43,061\tERROR services.py:1422 -- Failed to read dashboard.err file: cannot mmap an empty file. It is unexpected. Please report an issue to Ray github. https://github.com/ray-project/ray/issues\n",
      "2025-07-28 23:21:44,404\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'company_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mXGBoost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SSXGBoost\n\u001b[0;32m----> 2\u001b[0m split_index \u001b[38;5;241m=\u001b[39m \u001b[43mcompany_features\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# 分割索引，表示company特征与partner特征的分界\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m SSXGBoost(train_X1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], split_index)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_X, train_y, buckets_train, SSQuantiles, FedQuantiles)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'company_features' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SPURuntime pid=37042)\u001b[0m 2025-07-28 23:21:47.979 [warning] [openssl_factory.cc:OpensslDrbg:83] Yacl has been configured to use Yacl's entropy source, but unable to find one. Fallback to use openssl's default entropy srouce\n",
      "\u001b[36m(SPURuntime pid=37042)\u001b[0m 2025-07-28 23:21:47.980 [warning] [openssl_factory.cc:OpensslDrbg:83] Yacl has been configured to use Yacl's entropy source, but unable to find one. Fallback to use openssl's default entropy srouce\n"
     ]
    }
   ],
   "source": [
    "from XGBoost import SSXGBoost\n",
    "split_index = company_features.shape[1]  # 分割索引，表示company特征与partner特征的分界\n",
    "model = SSXGBoost(train_X1.shape[1], split_index)\n",
    "model.fit(train_X, train_y, buckets_train, SSQuantiles, FedQuantiles)\n",
    "\n",
    "y_pred = model.predict(test_X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "Accuracy = accuracy_score(test_y, y_pred)\n",
    "print(f\"Accuracy of SSXGBoost on breast dataset: {Accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
