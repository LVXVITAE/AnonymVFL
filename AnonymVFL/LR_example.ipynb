{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fcafac6",
   "metadata": {},
   "source": [
    "# LR示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ac923",
   "metadata": {},
   "source": [
    "以下示例仅用于说明LR的工作流程，目前仅支持单机测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e2a09",
   "metadata": {},
   "source": [
    "PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PSI import PSICompany, PSIPartner\n",
    "\n",
    "project_dir = os.path.dirname(os.path.abspath(''))\n",
    "data_dir = os.path.join(project_dir, 'Datasets', 'data', 'data')\n",
    "host_data = pd.read_csv(os.path.join(data_dir, 'breast_hetero_host.csv'))\n",
    "guest_data = pd.read_csv(os.path.join(data_dir, 'breast_hetero_guest.csv'))\n",
    "\n",
    "company_key, company_features = host_data['id'], host_data.drop(columns=['id'])\n",
    "partner_key, partner_features = guest_data['id'], guest_data.drop(columns=['id'])\n",
    "company_key = company_key.astype(str)\n",
    "partner_key = partner_key.astype(str)\n",
    "company = PSICompany(company_key, company_features)\n",
    "partner = PSIPartner(partner_key, partner_features)\n",
    "\n",
    "U_c, company_pk = company.exchange()\n",
    "U_g, partner_pk = partner.exchange()\n",
    "E_c, U_p, partner_pk = partner.exchange(U_c, company_pk)\n",
    "L, R_cI = company.compute_intersection(E_c, U_p, partner_pk)\n",
    "R_pI = partner.output_shares(L)\n",
    "company_share = R_cI[0]\n",
    "partner_share = R_pI[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12946001",
   "metadata": {},
   "source": [
    "此时share是`np.ndarray`类型。下面将其放入秘密共享设备spu中。\n",
    "目前我暂时还没有找到由share直接构造`SPUObject`的方法。可以暂时使用这个方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3dc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import MPCInitializer, sigmoid, softmax\n",
    "import secretflow as sf\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "mpc_init = MPCInitializer()\n",
    "company, partner, coordinator, spu = mpc_init.company, mpc_init.partner, mpc_init.coordinator, mpc_init.spu\n",
    "# 假设y由company持有\n",
    "label_holder = company\n",
    "\n",
    "def share2spu(X1 : np.ndarray, X2 : np.ndarray):\n",
    "    \"\"\"\n",
    "    X1：由Company持有的share\n",
    "    X2：由Partner持有的share\n",
    "    \"\"\"    \n",
    "    X1, X2 = jnp.array(X1,dtype=jnp.float32), jnp.array(X2,dtype=jnp.float32)\n",
    "    # 将X1，X2分别移动到spu\n",
    "    X1 = sf.to(company, X1).to(spu)\n",
    "    X2 = sf.to(partner, X2).to(spu)\n",
    "    # 再在spu内部相加，得到秘密共享的变量X\n",
    "    return spu(jnp.add)(X1, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f1ebb",
   "metadata": {},
   "source": [
    "划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_1, test_1, train_2, test_2 = train_test_split(\n",
    "    company_share, partner_share)\n",
    "train_X1, train_y1 = train_1[:, :-1], train_1[:, -1]\n",
    "train_X2, train_y2 = train_2[:, :-1], train_2[:, -1]\n",
    "test_X1, test_y1 = test_1[:, :-1], test_1[:, -1]\n",
    "test_X2, test_y2 = test_2[:, :-1], test_2[:, -1]\n",
    "\n",
    "test_X = share2spu(test_X1, test_X2)\n",
    "# 目前的模型在推理状态下，预测值按公开处理，因此测试集的y也公开\n",
    "test_y = test_y1 + test_y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d25f7",
   "metadata": {},
   "source": [
    "训练集划分batch以实现批量训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_features = train_X1.shape  # train_X1和train_X2的样本数相同\n",
    "\n",
    "batch_size = 1024\n",
    "Xs = []\n",
    "ys = []\n",
    "for j in range(0,num_samples,batch_size):\n",
    "    batch = min(batch_size,num_samples - j)\n",
    "    X_batch = share2spu(train_X1[j:j+batch], train_X2[j:j+batch])\n",
    "    y_batch = train_y1[j:j+batch] + train_y2[j:j+batch]\n",
    "    Xs.append(X_batch)\n",
    "    ys.append(y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369aed9e",
   "metadata": {},
   "source": [
    "训练指定的轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LR import SSLR\n",
    "\n",
    "model = SSLR(num_features)\n",
    "model.fit(Xs, ys, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479d153",
   "metadata": {},
   "source": [
    "或手动训练，绘制损失曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_iter = 20\n",
    "accs = []\n",
    "max_acc = 0\n",
    "for t in range(1,n_iter + 1):\n",
    "    print(f\"Epoch {t}\")\n",
    "    for X,y in tqdm(zip(Xs, ys)):\n",
    "        y_pred = model.forward(X)\n",
    "        model.backward(X, y, y_pred, 0.1 / t)\n",
    "\n",
    "    y_pred = model.predict(test_X)\n",
    "    Accracy = accuracy_score(test_y, y_pred)\n",
    "    if Accracy > max_acc:\n",
    "        max_acc = Accracy\n",
    "        print(f\"Iteration {t}, Accuracy: {Accracy:.4f}\")\n",
    "    accs.append(Accracy)\n",
    "\n",
    "plt.plot(accs,label = \"SSLR\",color = \"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
